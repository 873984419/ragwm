{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sunmengjie/lpz/vectordb/ragwatermark/src/models\n",
      "/home/sunmengjie/lpz/vectordb/ragwatermark/src/models\n"
     ]
    }
   ],
   "source": [
    "from watermark_role import Advisor, Checker, Visiter\n",
    "from  models import create_model\n",
    "from utils import load_beir_datasets, load_models\n",
    "from rag.vectorstore import VectorStore,check_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = 'trec-covid'\n",
    "eval_model_code = \"contriever\"\n",
    "score_function ='cosine'\n",
    "split = 'test'\n",
    "collection_name = eval_dataset+'_'+eval_model_code+'_'+score_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/contriever were not used when initializing Contriever: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing Contriever from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Contriever from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sunmengjie/lpz/vectordb/ragwatermark/datasets/trec-covid\n",
      "/home/sunmengjie/lpz/vectordb/ragwatermark/datasets/trec-covid\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92fc235fb529473a9f8bac0b94c64214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/171332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### load retriver model\n",
    "model, c_model, tokenizer, get_emb = load_models( eval_model_code)\n",
    "\n",
    "# load target queries and answers\n",
    "if  eval_dataset == 'msmarco':\n",
    "    corpus, queries, qrels = load_beir_datasets('msmarco', 'train')\n",
    "    \n",
    "else:\n",
    "    corpus, queries, qrels = load_beir_datasets( eval_dataset,  split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config_path = \"/home/sunmengjie/lpz/vectordb/ragwatermark/model_configs/gpt3.5_config.json\"\n",
    "llm = create_model( model_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collection_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m collection_exist, collection_len \u001b[38;5;241m=\u001b[39m check_collection(\u001b[43mcollection_name\u001b[49m)\n\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mset_device(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'collection_name' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "collection_exist, collection_len = check_collection(collection_name)\n",
    "torch.cuda.set_device(2)\n",
    "device = 'cuda'\n",
    " \n",
    "\n",
    "vectorstore = VectorStore(model, tokenizer, get_emb, corpus, device, collection_name, use_local=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.clean_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "visiter = Visiter(llm,  llm, vectorstore)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "checker = Checker(llm)\n",
    "response = checker.check_wm()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmunit = ['Authors', 'Objectivity', 'TREATS']\n",
    "rdoc = \"Authors uphold objectivity as a standard that they treat with utmost respect.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    }
   ],
   "source": [
    " \n",
    "checker.wm_unit =wmunit\n",
    "\n",
    "checker.rag_document=rdoc\n",
    "response = checker.check_wm()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: id_3431\n",
      "Add of existing embedding ID: id_3431\n",
      "Add of existing embedding ID: id_145509\n",
      "Add of existing embedding ID: id_158138\n",
      "Add of existing embedding ID: id_51626\n",
      "Add of existing embedding ID: id_67086\n",
      "Add of existing embedding ID: id_3962\n",
      "Add of existing embedding ID: id_138493\n",
      "Add of existing embedding ID: id_41187\n",
      "Add of existing embedding ID: id_12165\n",
      "Add of existing embedding ID: id_137968\n",
      "Add of existing embedding ID: id_156665\n",
      "Add of existing embedding ID: id_21573\n",
      "Add of existing embedding ID: id_151104\n",
      "Add of existing embedding ID: id_13591\n",
      "Add of existing embedding ID: id_107749\n",
      "Add of existing embedding ID: id_107749\n",
      "Add of existing embedding ID: id_143715\n",
      "Add of existing embedding ID: id_26573\n",
      "Add of existing embedding ID: id_165731\n",
      "Add of existing embedding ID: id_118035\n",
      "Add of existing embedding ID: id_156993\n",
      "Add of existing embedding ID: id_156993\n",
      "Add of existing embedding ID: id_126214\n",
      "Add of existing embedding ID: id_145509\n",
      "Add of existing embedding ID: id_158138\n",
      "Add of existing embedding ID: id_51626\n",
      "Add of existing embedding ID: id_67086\n",
      "Add of existing embedding ID: id_3962\n",
      "Add of existing embedding ID: id_138493\n",
      "Add of existing embedding ID: id_41187\n",
      "Add of existing embedding ID: id_12165\n",
      "Add of existing embedding ID: id_137968\n",
      "Add of existing embedding ID: id_156665\n",
      "Add of existing embedding ID: id_21573\n",
      "Add of existing embedding ID: id_151104\n",
      "Add of existing embedding ID: id_13591\n",
      "Add of existing embedding ID: id_107749\n",
      "Add of existing embedding ID: id_107749\n",
      "Add of existing embedding ID: id_143715\n",
      "Add of existing embedding ID: id_26573\n",
      "Add of existing embedding ID: id_165731\n",
      "Add of existing embedding ID: id_118035\n",
      "Add of existing embedding ID: id_156993\n",
      "Add of existing embedding ID: id_156993\n",
      "Add of existing embedding ID: id_126214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The relationship between authors and objectivity is explored in the book, which discusses the problematic nature of understanding universal values associated with objectivity in scientific research. The authors analyze how the science education research community conceptualizes the difficulties involved in accepting objectivity as an unquestioned virtue of the scientific enterprise.', 'id_15152')\n",
      "Authors uphold objectivity as a standard that they treat with utmost respect.\n",
      "No\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "visiter.wm_unit = wmunit\n",
    "visiter.rag_document = rdoc\n",
    "result = visiter.ask_wm()\n",
    "print(result)\n",
    "result = visiter.ask_wm_with_wt(visiter.rag_document)\n",
    "print(result)\n",
    "checker = Checker(llm)\n",
    "checker.rag_document = result\n",
    "response = checker.check_wm()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
